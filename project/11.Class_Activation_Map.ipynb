{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Class_Activation_Map.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "boaaNXQjiRpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## library import\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDxHiz2KireV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwbGSntkEqoJ",
        "colab_type": "text"
      },
      "source": [
        "## Data 준비하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bKuPTTfitCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## google drive에서 압축된 dataset download\n",
        "import gdown\n",
        "url = 'https://drive.google.com/uc?id=1dIR9ANjUsV9dWa0pS9J0c2KUGMfpIRG0'\n",
        "fname = 'oxford_pet.zip'\n",
        "gdown.download(url, fname, quiet=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caiDHg-siuNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## oxford_pet.zip이 보이는지 확인\n",
        "!ls -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdYtua7-AZw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 압축풀기\n",
        "!unzip -q oxford_pet.zip -d oxford_pet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWlYo19mAckW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 압축이 풀린 directory 확인\n",
        "!ls oxford_pet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUP8ce30AhSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## directory 설정\n",
        "cur_dir = os.getcwd()\n",
        "data_dir = os.path.join(cur_dir, 'oxford_pet')\n",
        "image_dir = os.path.join(data_dir, 'images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN8xhsaAAjj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## image file 수 확인\n",
        "image_files = [fname for fname in os.listdir(image_dir) if os.path.splitext(fname)[-1] == '.jpg']\n",
        "print(len(image_files))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTDYdL5dAlCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## image file들을 읽어서 channel이 3이 아닌 image는 삭제\n",
        "for image_file in image_files:\n",
        "  image_path = os.path.join(image_dir, image_file)\n",
        "  image = Image.open(image_path)\n",
        "  image_mode = image.mode\n",
        "  if image_mode != 'RGB':\n",
        "    print(image_file, image_mode)\n",
        "    image = np.asarray(image)\n",
        "    print(image.shape)\n",
        "    os.remove(image_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cppg8h2VAw4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## image file 수 확인\n",
        "image_files = [fname for fname in os.listdir(image_dir) if os.path.splitext(fname)[-1] == '.jpg']\n",
        "print(len(image_files))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "222XfHgfBEn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_list = set()\n",
        "for image_file in image_files:\n",
        "    file_name = os.path.splitext(image_file)[0]\n",
        "    class_name = re.sub('_\\d+', '', file_name)\n",
        "    class_list.add(class_name)\n",
        "class_list = list(class_list)\n",
        "print(len(class_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgAn11sPBoCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_list.sort()\n",
        "class_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSD0OPZiBqcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class2idx = {cls:idx for idx, cls in enumerate(class_list)}\n",
        "class2idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYVLpAqbCDVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## train, validation directory 생성\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "val_dir = os.path.join(data_dir, 'validation')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BvTqU94CNDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_files.sort()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bWy45HtCRfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_files[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vtk6sPRCSmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnt = 0\n",
        "previous_class = \"\"\n",
        "for image_file in image_files:\n",
        "    file_name = os.path.splitext(image_file)[0]\n",
        "    class_name = re.sub('_\\d+', '', file_name)\n",
        "    if class_name == previous_class:\n",
        "        cnt += 1\n",
        "    else:\n",
        "        cnt = 1\n",
        "    if cnt <= 160:\n",
        "        cpath = train_dir\n",
        "    else:\n",
        "        cpath = val_dir\n",
        "    image_path = os.path.join(image_dir, image_file)\n",
        "    shutil.copy(image_path, cpath)\n",
        "    previous_class = class_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBFCxHS4DUPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = os.listdir(train_dir)\n",
        "val_images = os.listdir(val_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QozFeSbWDXtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(train_images), len(val_images))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k346RhAjDtZp",
        "colab_type": "text"
      },
      "source": [
        "## TFRecord 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69VyTmqqDc2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 224"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa4QauQ7DsCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## TFRecord 저장할 directory와 file 경로 설정\n",
        "tfr_dir = os.path.join(data_dir, 'tfrecord')\n",
        "os.makedirs(tfr_dir, exist_ok=True)\n",
        "\n",
        "tfr_train_dir = os.path.join(tfr_dir, 'cls_train.tfr')\n",
        "tfr_val_dir = os.path.join(tfr_dir, 'cls_val.tfr')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guqSU7DRjKoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## TFRecord writer 생성\n",
        "writer_train = tf.io.TFRecordWriter(tfr_train_dir)\n",
        "writer_val = tf.io.TFRecordWriter(tfr_val_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9C7LmF3Fl4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The following functions can be used to convert a value to a type compatible\n",
        "# with tf.Example.\n",
        "\n",
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrDR5d2SGZBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_train = 0\n",
        "\n",
        "train_files = os.listdir(train_dir)\n",
        "for train_file in train_files:\n",
        "  train_path = os.path.join(train_dir, train_file)\n",
        "  image = Image.open(train_path)\n",
        "  image = image.resize((IMG_SIZE, IMG_SIZE))\n",
        "  bimage = image.tobytes()\n",
        "\n",
        "  file_name = os.path.splitext(train_file)[0] #Bangal_101\n",
        "  class_name = re.sub('_\\d+', '', file_name)\n",
        "  class_num = class2idx[class_name]\n",
        "\n",
        "  if file_name[0].islower(): # dog\n",
        "    bi_cls_num = 0\n",
        "  else: # cat\n",
        "    bi_cls_num = 1\n",
        "\n",
        "  example = tf.train.Example(features=tf.train.Features(feature={\n",
        "      'image': _bytes_feature(bimage),\n",
        "      'cls_num': _int64_feature(class_num),\n",
        "      'bi_cls_num': _int64_feature(bi_cls_num)\n",
        "  }))\n",
        "  writer_train.write(example.SerializeToString())\n",
        "  n_train += 1\n",
        "\n",
        "writer_train.close()\n",
        "print(n_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0HL5fAeHm7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_val = 0\n",
        "\n",
        "val_files = os.listdir(val_dir)\n",
        "for val_file in val_files:\n",
        "  val_path = os.path.join(val_dir, val_file)\n",
        "  image = Image.open(val_path)\n",
        "  image = image.resize((IMG_SIZE, IMG_SIZE))\n",
        "  bimage = image.tobytes()\n",
        "\n",
        "  file_name = os.path.splitext(val_file)[0] #Bangal_101\n",
        "  class_name = re.sub('_\\d+', '', file_name)\n",
        "  class_num = class2idx[class_name]\n",
        "\n",
        "  if file_name[0].islower(): # dog\n",
        "    bi_cls_num = 0\n",
        "  else: # cat\n",
        "    bi_cls_num = 1\n",
        "\n",
        "  example = tf.train.Example(features=tf.train.Features(feature={\n",
        "      'image': _bytes_feature(bimage),\n",
        "      'cls_num': _int64_feature(class_num),\n",
        "      'bi_cls_num': _int64_feature(bi_cls_num)\n",
        "  }))\n",
        "  writer_val.write(example.SerializeToString())\n",
        "  n_val += 1\n",
        "\n",
        "writer_val.close()\n",
        "print(n_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsZz6VdvjGYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -l $tfr_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9l6lGpGJA0a",
        "colab_type": "text"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSq3fUQ8KRqV",
        "colab_type": "text"
      },
      "source": [
        "### 37개 Class로 classification 하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q67RpcOWIHk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Hyper Parameters\n",
        "N_CLASS = len(class_list)\n",
        "N_EPOCHS = 20\n",
        "N_BATCH = 40\n",
        "N_TRAIN = n_train\n",
        "N_VAL = n_val\n",
        "IMG_SIZE = 224\n",
        "learning_rate = 0.0001\n",
        "steps_per_epoch = N_TRAIN / N_BATCH\n",
        "validation_steps = int(np.ceil(N_VAL / N_BATCH))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ItNVoidIQNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## tfrecord file을 data로 parsing해주는 function\n",
        "def _parse_function(tfrecord_serialized):\n",
        "    features={'image': tf.io.FixedLenFeature([], tf.string),\n",
        "              'cls_num': tf.io.FixedLenFeature([], tf.int64),\n",
        "              'bi_cls_num': tf.io.FixedLenFeature([], tf.int64)\n",
        "             }\n",
        "    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
        "    \n",
        "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)    \n",
        "    image = tf.reshape(image, [IMG_SIZE, IMG_SIZE, 3])\n",
        "    image = tf.cast(image, tf.float32)/255. \n",
        "\n",
        "    label = tf.cast(parsed_features['cls_num'], tf.int64)\n",
        "    bi_cls_label = tf.cast(parsed_features['bi_cls_num'], tf.int64)\n",
        "\n",
        "    return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g4htxQRIsPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## train dataset 만들기\n",
        "train_dataset = tf.data.TFRecordDataset(tfr_train_dir)\n",
        "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "train_dataset = train_dataset.shuffle(N_TRAIN).prefetch(\n",
        "    tf.data.experimental.AUTOTUNE).batch(N_BATCH).repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP6T4iHwJK3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## validation dataset 만들기\n",
        "val_dataset = tf.data.TFRecordDataset(tfr_val_dir)\n",
        "val_dataset = val_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(N_BATCH).repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS8zrviiJMEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for images, labels in train_dataset.take(5):\n",
        "  plt.imshow(images[0])\n",
        "  title = class_list[labels[0].numpy()]\n",
        "  plt.title(title)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10S3kimgMLsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.layers import Conv2D, ReLU, MaxPooling2D, Dense, BatchNormalization, GlobalAveragePooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLX1lM98Q_Xo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mobilenetv2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkQ3_RtHMLnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mv_model():\n",
        "  mobilenetv2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "  gap = GlobalAveragePooling2D()(mobilenetv2.output)\n",
        "  output = Dense(N_CLASS, activation='softmax', name='output_layer')(gap)\n",
        "  return keras.Model(inputs=mobilenetv2.input, outputs=output)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsbvRQSdQ1sb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Create model, compile & summary\n",
        "model1 = create_mv_model()\n",
        "\n",
        "## learning rate scheduing\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n",
        "                                                          decay_steps=steps_per_epoch*5,\n",
        "                                                          decay_rate=0.5,\n",
        "                                                          staircase=True)\n",
        "model1.compile(optimizer=tf.keras.optimizers.Adam(lr_schedule),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOr-woOQQ1yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model1.fit(\n",
        "    train_dataset,\n",
        "    epochs=N_EPOCHS,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_dataset,\n",
        "    validation_steps=validation_steps\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3toSf692KdBj",
        "colab_type": "text"
      },
      "source": [
        "### Class Activation Map 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRSxM_xvlIy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQlBaOgnn5UB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_fmap = model1.get_layer(name='out_relu').output\n",
        "new_model1 = keras.models.Model(model1.input, target_fmap)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpbUewXRoClH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = model1.get_layer(name='output_layer').get_weights()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoOR3sxBsf6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sfzRDLIsg8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for images, labels in val_dataset.take(5):\n",
        "  plt.figure(figsize=(10,6))\n",
        "\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.imshow(images[0])\n",
        "  prediction = model1.predict(images)\n",
        "  pred_class = np.argmax(prediction[0], -1)\n",
        "  title = class_list[pred_class]\n",
        "  plt.title(title)\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  fmap = new_model1(images)\n",
        "  weights_cam = weights[:,pred_class]\n",
        "  camsum = np.zeros((7,7))\n",
        "  for i in range(1280):\n",
        "    camsum += weights_cam[i]*fmap[0,:,:,i]\n",
        "  camsum = camsum / 1280\n",
        "  plt.imshow(camsum)\n",
        "  \n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJOHlMB9Khea",
        "colab_type": "text"
      },
      "source": [
        "### 고양이/개 2 Class로 classification 하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7ZSXmpTtbhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_CLASS = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlWHrG4fv0bC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## tfrecord file을 data로 parsing해주는 function\n",
        "def _parse_function(tfrecord_serialized):\n",
        "    features={'image': tf.io.FixedLenFeature([], tf.string),\n",
        "              'cls_num': tf.io.FixedLenFeature([], tf.int64),\n",
        "              'bi_cls_num': tf.io.FixedLenFeature([], tf.int64)\n",
        "             }\n",
        "    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
        "    \n",
        "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)    \n",
        "    image = tf.reshape(image, [IMG_SIZE, IMG_SIZE, 3])\n",
        "    image = tf.cast(image, tf.float32)/255. \n",
        "\n",
        "    label = tf.cast(parsed_features['cls_num'], tf.int64)\n",
        "    bi_cls_label = tf.cast(parsed_features['bi_cls_num'], tf.int64)\n",
        "\n",
        "    return image, bi_cls_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EUZ8Vw6lwK4B",
        "colab": {}
      },
      "source": [
        "## train dataset 만들기\n",
        "train_dataset = tf.data.TFRecordDataset(tfr_train_dir)\n",
        "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "train_dataset = train_dataset.shuffle(N_TRAIN).prefetch(\n",
        "    tf.data.experimental.AUTOTUNE).batch(N_BATCH).repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8pkEDcxgwK4G",
        "colab": {}
      },
      "source": [
        "## validation dataset 만들기\n",
        "val_dataset = tf.data.TFRecordDataset(tfr_val_dir)\n",
        "val_dataset = val_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(N_BATCH).repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LyJipX20wK4I",
        "colab": {}
      },
      "source": [
        "for images, labels in train_dataset.take(5):\n",
        "  plt.imshow(images[0])\n",
        "  if labels[0] == 0:\n",
        "    title = 'Dog'\n",
        "  else:\n",
        "    title = 'Cat'\n",
        "  plt.title(title)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "79EtYlGRwK4L",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.layers import Conv2D, ReLU, MaxPooling2D, Dense, BatchNormalization, GlobalAveragePooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OBKzAblAwK4Q",
        "colab": {}
      },
      "source": [
        "def create_mv_model():\n",
        "  mobilenetv2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "  gap = GlobalAveragePooling2D()(mobilenetv2.output)\n",
        "  output = Dense(N_CLASS, activation='softmax', name='output_layer')(gap)\n",
        "  return keras.Model(inputs=mobilenetv2.input, outputs=output)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d-VshHQEwK4S",
        "colab": {}
      },
      "source": [
        "## Create model, compile & summary\n",
        "model2 = create_mv_model()\n",
        "\n",
        "## learning rate scheduing\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n",
        "                                                          decay_steps=steps_per_epoch*5,\n",
        "                                                          decay_rate=0.5,\n",
        "                                                          staircase=True)\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(lr_schedule),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model2.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KyAmn_WdwK4U",
        "colab": {}
      },
      "source": [
        "history = model2.fit(\n",
        "    train_dataset,\n",
        "    epochs=N_EPOCHS,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_dataset,\n",
        "    validation_steps=validation_steps\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gslgpJ4MKwuh"
      },
      "source": [
        "### Class Activation Map 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N1ILudqswK4Y",
        "colab": {}
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-egKnM1pwK4a",
        "colab": {}
      },
      "source": [
        "target_fmap = model2.get_layer(name='out_relu').output\n",
        "new_model2 = keras.models.Model(model2.input, target_fmap)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GMyXsAj-wK4c",
        "colab": {}
      },
      "source": [
        "weights = model2.get_layer(name='output_layer').get_weights()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LrIT0KguwK4e",
        "colab": {}
      },
      "source": [
        "weights.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qClWWTS3wK4g",
        "colab": {}
      },
      "source": [
        "for images, labels in val_dataset.take(5):\n",
        "  plt.figure(figsize=(10,6))\n",
        "\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.imshow(images[0])\n",
        "  prediction = model2.predict(images)\n",
        "  pred_class = np.argmax(prediction[0], -1)\n",
        "  if labels[0] == 0:\n",
        "    title = 'Dog'\n",
        "  else:\n",
        "    title = 'Cat'\n",
        "  plt.title(title)\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  fmap = new_model2(images)\n",
        "  weights_cam = weights[:,pred_class]\n",
        "  camsum = np.zeros((7,7))\n",
        "  for i in range(1280):\n",
        "    camsum += weights_cam[i]*fmap[0,:,:,i]\n",
        "  camsum = camsum / 1280\n",
        "  plt.title('Class Activation Map')\n",
        "  plt.imshow(camsum)\n",
        "  \n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nH4BNyKKzYZ",
        "colab_type": "text"
      },
      "source": [
        "### 2개 model의 CAM 비교하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B6FoLc9zmYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for images, labels in val_dataset.take(10):\n",
        "  plt.figure(figsize=(15,6))\n",
        "\n",
        "  plt.subplot(1,3,1)\n",
        "  plt.imshow(images[0])    \n",
        "  plt.title('Input Image')\n",
        "\n",
        "  plt.subplot(1,3,2)\n",
        "  prediction1 = model1.predict(images)\n",
        "  pred_class1 = np.argmax(prediction1[0], -1)\n",
        "  fmap1 = new_model1(images)\n",
        "  weights1 = model1.get_layer(name='output_layer').get_weights()[0]\n",
        "  weights_cam1 = weights1[:,pred_class1]\n",
        "  camsum1 = np.zeros((7,7))\n",
        "  for i in range(1280):\n",
        "    camsum1 += weights_cam1[i]*fmap1[0,:,:,i]\n",
        "  camsum1 = camsum1 / 1280\n",
        "  plt.title('CAM-37 class')\n",
        "  plt.imshow(camsum1)\n",
        "\n",
        "  plt.subplot(1,3,3)\n",
        "  prediction2 = model2.predict(images)\n",
        "  pred_class2 = np.argmax(prediction2[0], -1)\n",
        "  fmap2 = new_model2(images)\n",
        "  weights2 = model2.get_layer(name='output_layer').get_weights()[0]\n",
        "  weights_cam2 = weights2[:,pred_class2]\n",
        "  camsum2 = np.zeros((7,7))\n",
        "  for i in range(1280):\n",
        "    camsum2 += weights_cam2[i]*fmap2[0,:,:,i]\n",
        "  camsum2 = camsum2 / 1280\n",
        "  plt.title('CAM-2 class')\n",
        "  plt.imshow(camsum2)\n",
        "  \n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuauxFKSBGZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}