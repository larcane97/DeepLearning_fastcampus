{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Oxford_Pet_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOlR5SRQ_rRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## library import\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "from PIL import Image\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q3wx3rfAKD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INMNWadsDycA",
        "colab_type": "text"
      },
      "source": [
        "## Data 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu7sQGmLANhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## google drive에서 압축된 dataset download\n",
        "import gdown\n",
        "url = 'https://drive.google.com/uc?id=1dIR9ANjUsV9dWa0pS9J0c2KUGMfpIRG0'\n",
        "fname = 'oxford_pet.zip'\n",
        "gdown.download(url, fname, quiet=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDkv_v3rASc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## oxford_pet.zip이 보이는지 확인\n",
        "!ls -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdYtua7-AZw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 압축풀기\n",
        "!unzip -q oxford_pet.zip -d oxford_pet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWlYo19mAckW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 압축이 풀린 directory 확인\n",
        "!ls oxford_pet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUP8ce30AhSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## directory 설정\n",
        "cur_dir = os.getcwd()\n",
        "data_dir = os.path.join(cur_dir, 'oxford_pet')\n",
        "image_dir = os.path.join(data_dir, 'images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN8xhsaAAjj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## image file 수 확인\n",
        "image_files = [fname for fname in os.listdir(image_dir) if os.path.splitext(fname)[-1] == '.jpg']\n",
        "print(len(image_files))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTDYdL5dAlCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## image file들을 읽어서 channel이 3이 아닌 image는 삭제\n",
        "for image_file in image_files:\n",
        "  image_path = os.path.join(image_dir, image_file)\n",
        "  image = Image.open(image_path)\n",
        "  image_mode = image.mode\n",
        "  if image_mode != 'RGB':\n",
        "    print(image_file, image_mode)\n",
        "    image = np.asarray(image)\n",
        "    print(image.shape)\n",
        "    os.remove(image_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cppg8h2VAw4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## image file 수 확인\n",
        "image_files = [fname for fname in os.listdir(image_dir) if os.path.splitext(fname)[-1] == '.jpg']\n",
        "print(len(image_files))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "222XfHgfBEn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_list = set()\n",
        "for image_file in image_files:\n",
        "    file_name = os.path.splitext(image_file)[0]\n",
        "    class_name = re.sub('_\\d+', '', file_name)\n",
        "    class_list.add(class_name)\n",
        "class_list = list(class_list)\n",
        "print(len(class_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgAn11sPBoCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_list.sort()\n",
        "class_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSR0PnMuB-RB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_list[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSD0OPZiBqcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class2idx = {cls:idx for idx, cls in enumerate(class_list)}\n",
        "class2idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28uLAxq7B28m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class2idx['Bengal']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYVLpAqbCDVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## train, validation directory 생성\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "val_dir = os.path.join(data_dir, 'validation')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BvTqU94CNDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_files.sort()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bWy45HtCRfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_files[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vtk6sPRCSmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnt = 0\n",
        "previous_class = \"\"\n",
        "for image_file in image_files:\n",
        "    file_name = os.path.splitext(image_file)[0]\n",
        "    class_name = re.sub('_\\d+', '', file_name)\n",
        "    if class_name == previous_class:\n",
        "        cnt += 1\n",
        "    else:\n",
        "        cnt = 1\n",
        "    if cnt <= 160:\n",
        "        cpath = train_dir\n",
        "    else:\n",
        "        cpath = val_dir\n",
        "    image_path = os.path.join(image_dir, image_file)\n",
        "    shutil.copy(image_path, cpath)\n",
        "    previous_class = class_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBFCxHS4DUPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = os.listdir(train_dir)\n",
        "val_images = os.listdir(val_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QozFeSbWDXtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(train_images), len(val_images))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkE29AuyDZke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWM5lj9-DbKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_images[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k346RhAjDtZp",
        "colab_type": "text"
      },
      "source": [
        "## TFRecord File 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69VyTmqqDc2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 224"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa4QauQ7DsCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## TFRecord 저장할 directory와 file 경로 설정\n",
        "tfr_dir = os.path.join(data_dir, 'tfrecord')\n",
        "os.makedirs(tfr_dir, exist_ok=True)\n",
        "\n",
        "tfr_train_dir = os.path.join(tfr_dir, 'cls_train.tfr')\n",
        "tfr_val_dir = os.path.join(tfr_dir, 'cls_val.tfr')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D2rJ_WQD7wh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## TFRecord writer 생성\n",
        "writer_train = tf.io.TFRecordWriter(tfr_train_dir)\n",
        "writer_val = tf.io.TFRecordWriter(tfr_val_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9C7LmF3Fl4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The following functions can be used to convert a value to a type compatible\n",
        "# with tf.Example.\n",
        "\n",
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrDR5d2SGZBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Training data로 tfrecord 만들기\n",
        "n_train = 0\n",
        "\n",
        "train_files = os.listdir(train_dir)\n",
        "for train_file in train_files:\n",
        "  train_path = os.path.join(train_dir, train_file)\n",
        "  image = Image.open(train_path)\n",
        "  image = image.resize((IMG_SIZE, IMG_SIZE))\n",
        "  bimage = image.tobytes()\n",
        "\n",
        "  file_name = os.path.splitext(train_file)[0] #Bangal_101\n",
        "  class_name = re.sub('_\\d+', '', file_name)\n",
        "  class_num = class2idx[class_name]\n",
        "\n",
        "  example = tf.train.Example(features=tf.train.Features(feature={\n",
        "      'image': _bytes_feature(bimage),\n",
        "      'cls_num': _int64_feature(class_num)\n",
        "  }))\n",
        "  writer_train.write(example.SerializeToString())\n",
        "  n_train += 1\n",
        "\n",
        "writer_train.close()\n",
        "print(n_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0HL5fAeHm7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Validation data로 tfrecord 만들기\n",
        "n_val = 0\n",
        "\n",
        "val_files = os.listdir(val_dir)\n",
        "for val_file in val_files:\n",
        "  val_path = os.path.join(val_dir, val_file)\n",
        "  image = Image.open(val_path)\n",
        "  image = image.resize((IMG_SIZE, IMG_SIZE))\n",
        "  bimage = image.tobytes()\n",
        "\n",
        "  file_name = os.path.splitext(val_file)[0] #Bangal_101\n",
        "  class_name = re.sub('_\\d+', '', file_name)\n",
        "  class_num = class2idx[class_name]\n",
        "\n",
        "  example = tf.train.Example(features=tf.train.Features(feature={\n",
        "      'image': _bytes_feature(bimage),\n",
        "      'cls_num': _int64_feature(class_num)\n",
        "  }))\n",
        "  writer_val.write(example.SerializeToString())\n",
        "  n_val += 1\n",
        "\n",
        "writer_val.close()\n",
        "print(n_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1JBx-YMH8iP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -l $tfr_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9l6lGpGJA0a",
        "colab_type": "text"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q67RpcOWIHk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Hyper Parameters\n",
        "N_CLASS = len(class_list)\n",
        "N_EPOCHS = 20\n",
        "N_BATCH = 40\n",
        "N_TRAIN = n_train\n",
        "N_VAL = n_val\n",
        "IMG_SIZE = 224\n",
        "learning_rate = 0.0001\n",
        "steps_per_epoch = N_TRAIN / N_BATCH\n",
        "validation_steps = int(np.ceil(N_VAL / N_BATCH))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ItNVoidIQNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## tfrecord file을 data로 parsing해주는 function\n",
        "def _parse_function(tfrecord_serialized):\n",
        "    features={'image': tf.io.FixedLenFeature([], tf.string),\n",
        "              'cls_num': tf.io.FixedLenFeature([], tf.int64)              \n",
        "             }\n",
        "    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
        "    \n",
        "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)    \n",
        "    image = tf.reshape(image, [IMG_SIZE, IMG_SIZE, 3])\n",
        "    image = tf.cast(image, tf.float32)/255. \n",
        "\n",
        "    label = tf.cast(parsed_features['cls_num'], tf.int64)\n",
        "\n",
        "    return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g4htxQRIsPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## train dataset 만들기\n",
        "train_dataset = tf.data.TFRecordDataset(tfr_train_dir)\n",
        "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "train_dataset = train_dataset.shuffle(N_TRAIN).prefetch(\n",
        "    tf.data.experimental.AUTOTUNE).batch(N_BATCH).repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP6T4iHwJK3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## validation dataset 만들기\n",
        "val_dataset = tf.data.TFRecordDataset(tfr_val_dir)\n",
        "val_dataset = val_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(N_BATCH).repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS8zrviiJMEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image, label in train_dataset.take(5):\n",
        "  plt.imshow(image[0])\n",
        "  title = class_list[label[0].numpy()]\n",
        "  plt.title(title)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AAHr46_JNk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sequential API를 사용하여 model 구성\n",
        "def create_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='SAME', \n",
        "                                  input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='SAME'))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='SAME'))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='SAME'))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='SAME'))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(1024, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(0.4))\n",
        "    model.add(keras.layers.Dense(N_CLASS, activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwtYqXyuJSY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Create model, compile & summary\n",
        "model = create_model()\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p0pgrKWJYcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=N_EPOCHS,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_dataset,\n",
        "    validation_steps=validation_steps\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qoyfky38LJO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sequential API를 사용하여 model 구성\n",
        "def create_bn_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters=32, kernel_size=3, padding='SAME', \n",
        "                                  input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.ReLU())\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters=64, kernel_size=3, padding='SAME'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.ReLU())\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters=128, kernel_size=3, padding='SAME'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.ReLU())\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters=256, kernel_size=3, padding='SAME'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.ReLU())\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters=256, kernel_size=3, padding='SAME'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.ReLU())\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(1024))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.ReLU())    \n",
        "    model.add(keras.layers.Dense(N_CLASS, activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je2EsPg-Uc1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Create model, compile & summary\n",
        "model = create_bn_model()\n",
        "\n",
        "## learning rate scheduing\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n",
        "                                                          decay_steps=steps_per_epoch*5,\n",
        "                                                          decay_rate=0.5,\n",
        "                                                          staircase=True)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr_schedule),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvmb19WYUfGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=N_EPOCHS,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_dataset,\n",
        "    validation_steps=validation_steps\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PoII6syeJO4",
        "colab_type": "text"
      },
      "source": [
        "### Pretrained MobileNetV2 사용하여 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5xF7COaEZVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb0-ZgBEeNNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.layers import Conv2D, ReLU, MaxPooling2D, Dense, BatchNormalization, GlobalAveragePooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vy6BRv5eQIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mobilenetv2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iMMVs1WeRpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mobilenetv2.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQgIKM1CeVbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mv_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(mobilenetv2)\n",
        "  model.add(GlobalAveragePooling2D())  \n",
        "  model.add(Dense(N_CLASS, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjw_rYd1edcp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Create model, compile & summary\n",
        "model = create_mv_model()\n",
        "\n",
        "## learning rate scheduing\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n",
        "                                                          decay_steps=steps_per_epoch*5,\n",
        "                                                          decay_rate=0.5,\n",
        "                                                          staircase=True)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr_schedule),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3AqznXIeerq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=N_EPOCHS,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_dataset,\n",
        "    validation_steps=validation_steps\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHPouJrJFH-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}